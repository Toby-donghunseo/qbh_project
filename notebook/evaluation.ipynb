{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import _pickle as pickle\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import defaultdict, OrderedDict\n",
    "import numpy as np\n",
    "\n",
    "from train import load_hparams, load_model, load_checkpoint, make_aug_param_dictionary\n",
    "from model import CnnEncoder\n",
    "from data_utils import WindowedContourSet, ContourCollate, HummingPairSet, get_song_ids_of_selected_genre\n",
    "from validation import get_contour_embeddings, cal_ndcg_single\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import random\n",
    "import pandas as pd\n",
    "import humming_data_utils as utils\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_model(ckpt_dir):\n",
    "    model_path = Path(ckpt_dir)\n",
    "    # hparams = load_hparams(model_path / 'hparams.dat')\n",
    "    with open(model_path / 'hparams.dat', 'rb') as f:\n",
    "        hparams = pickle.load(f)\n",
    "    model = CnnEncoder(hparams).cuda()\n",
    "    model, _, _, _ = load_checkpoint(model_path/'checkpoint_best.pt', model, None, train_on_humming=True)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def prepare_dataset(data_dir='/home/svcapp/userdata/flo_data_backup/', selected_genres=[4, 12, 13, 17, 10, 7,15, 11, 9], num_workers=2, min_vocal_ratio=0.5):\n",
    "\n",
    "    with open('flo_metadata_220k.dat', 'rb') as f:\n",
    "        metadata = pickle.load(f)\n",
    "    with open('humm_db_ids.dat', 'rb') as f:\n",
    "        humm_ids = pickle.load(f)\n",
    "\n",
    "    song_ids = get_song_ids_of_selected_genre(metadata, selected_genre=selected_genres)\n",
    "    song_ids += humm_ids\n",
    "#     song_ids = humm_ids\n",
    "    # song_ids = [427396913, 5466183, 30894451, 421311716, 420497440]\n",
    "    entireset = WindowedContourSet(data_dir, aug_weights=[], song_ids=song_ids, set_type='entire', pre_load=False, num_aug_samples=0, num_neg_samples=0, min_vocal_ratio=min_vocal_ratio)\n",
    "\n",
    "    entire_loader = DataLoader(entireset, 512, shuffle=True,num_workers=num_workers,\n",
    "        collate_fn=ContourCollate(0, 0, for_cnn=True), pin_memory=False, drop_last=False)\n",
    "\n",
    "    # with open(hparams.humming_path, \"rb\") as f:\n",
    "    with open('/home/svcapp/userdata/flo_melody/humming_db_contour_pairs.dat', 'rb') as f:\n",
    "        contour_pairs = pickle.load(f)\n",
    "\n",
    "    humm_test_set = HummingPairSet(contour_pairs, [], \"test\",[], num_aug_samples=0, num_neg_samples=0)\n",
    "    humm_test_loader = DataLoader(humm_test_set, 1, shuffle=False,num_workers=num_workers,\n",
    "        collate_fn=ContourCollate(0, 0, for_cnn=True), pin_memory=True, drop_last=False)\n",
    "\n",
    "    selected_100, selected_900 = utils.load_meta_from_excel(\"/home/svcapp/userdata/humming_db/Spec.xlsx\")\n",
    "\n",
    "    meta_in_song_key = {x['track_id']: x for x in metadata}\n",
    "    for song in selected_100.to_dict('records'):\n",
    "        meta_in_song_key[song['track_id']] = song\n",
    "    for song in selected_900.to_dict('records'):\n",
    "        meta_in_song_key[song['track_id']] = song\n",
    "    return entire_loader, humm_test_loader, meta_in_song_key\n",
    "\n",
    "\n",
    "def evaluate(model, humm_test_loader, total_embs, total_song_ids, unique_ids, index_by_id):\n",
    "    model.eval()\n",
    "    num_correct_answer = 0\n",
    "    total_success = []\n",
    "    total_recommends = []\n",
    "    total_test_ids = []\n",
    "    total_rank = []\n",
    "    with torch.no_grad():\n",
    "    #     total_embs, total_song_ids = get_contour_embeddings(model, entire_loader)\n",
    "        for j, batch in enumerate(humm_test_loader):\n",
    "            contours, song_ids = batch\n",
    "            anchor = model(contours.cuda())\n",
    "            anchor_norm = anchor / anchor.norm(dim=1)[:, None]\n",
    "            similarity = torch.mm(anchor_norm, total_embs.transpose(0,1))\n",
    "            max_similarity_by_song = torch.max(similarity[:,index_by_id], dim=-1)[0]\n",
    "\n",
    "            corresp_melody_ids = torch.where(total_song_ids==song_ids)[0]\n",
    "            if len(corresp_melody_ids) ==0:\n",
    "                max_similarity = -1\n",
    "            else:\n",
    "                max_similarity = torch.max(similarity[:, corresp_melody_ids])\n",
    "            max_rank = torch.sum(max_similarity_by_song > max_similarity)\n",
    "            recommends = torch.topk(max_similarity_by_song, k=30, dim=-1)[1]\n",
    "            recommends = unique_ids[recommends]\n",
    "            top10_success = [ int(int(song_ids[i]) in recommends[i,:10].tolist()) for i in range(recommends.shape[0])]\n",
    "            total_success += top10_success\n",
    "            total_recommends.append(recommends)\n",
    "            total_test_ids.append(song_ids)\n",
    "            total_rank.append(max_rank.item())\n",
    "            \n",
    "            num_correct_answer += sum(top10_success)\n",
    "    print(num_correct_answer / len(humm_test_loader.dataset))\n",
    "    total_recommends = torch.cat(total_recommends, dim=0).cpu().numpy()\n",
    "    total_test_ids = torch.cat(total_test_ids, dim=0).cpu().numpy()\n",
    "    return total_recommends, total_test_ids, total_rank\n",
    "\n",
    "def get_index_by_id(total_song_ids):\n",
    "    out = []\n",
    "    unique_ids = list(set(total_song_ids.tolist()))\n",
    "    for id in unique_ids:\n",
    "        out.append(torch.where(total_song_ids==id)[0])\n",
    "    max_len = max([len(x) for x in out])\n",
    "    dummy = torch.zeros((len(unique_ids), max_len), dtype=torch.long)\n",
    "    for i, ids in enumerate(out):\n",
    "        dummy[i,:len(ids)] = ids\n",
    "        dummy[i, len(ids):] = ids[-1]\n",
    "    return torch.LongTensor(unique_ids), dummy\n",
    "\n",
    "def get_similarity_by_id(similarity, unique_ids, index_by_ids):\n",
    "    return\n",
    "\n",
    "def convert_result_to_dict(ids, ranks, meta):\n",
    "    out = defaultdict(list)\n",
    "    for id, r in zip(ids, ranks):\n",
    "        out[meta[id]['artist_name'] + ' - ' + meta[id]['track_name']].append(r)\n",
    "    return dict(out)\n",
    "\n",
    "def save_dict_result_to_csv(adict):\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font_path = 'malgun.ttf'\n",
    "font_name = fm.FontProperties(fname=font_path, size=50).get_name()\n",
    "plt.rc('font', family=font_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta[427396913]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flo_test_list = pd.read_csv('flo_test_list.csv')\n",
    "flo_test_meta = {x['track id ']: x for x in flo_test_list.to_dict('records')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flo_test_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entire_loader, humm_test_loader, meta = prepare_dataset(data_dir='/home/svcapp/t2meta/flo_new_music/music_100k/', min_vocal_ratio=0.3, selected_genres=[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# worker_ids = [480785, 401032, 482492, 482457, 483461]\n",
    "worker_ids = [482492]\n",
    "model_dir = Path('/home/svcapp/t2meta/qbh_model')\n",
    "for id in worker_ids:\n",
    "    ckpt_dir = next(model_dir.glob(f\"worker_{id}*\"))\n",
    "    model = load_model(ckpt_dir)\n",
    "    total_embs, total_song_ids = get_contour_embeddings(model, entire_loader)\n",
    "    unique_ids, index_by_id = get_index_by_id(total_song_ids)\n",
    "    total_recommends, total_test_ids, total_rank = evaluate(model, humm_test_loader, total_embs, total_song_ids, unique_ids, index_by_id)\n",
    "    out = convert_result_to_dict(total_test_ids, total_rank, meta)\n",
    "    detail_out = convert_result_to_rec_title(total_test_ids, total_recommends, total_rank, meta)\n",
    "    keys = sorted(out.keys())\n",
    "    rank_array = np.asarray([out[x] for x in keys])\n",
    "    fig = plt.figure(figsize=(20,20))\n",
    "    ax = plt.gca()\n",
    "    plt.imshow(1/(rank_array+1))\n",
    "    plt.colorbar()\n",
    "    ax.set_yticks(list(range(len(rank_array))))\n",
    "    ax.set_yticklabels(keys)\n",
    "    for label in ax.get_yticklabels() :\n",
    "        label.set_fontproperties(font_prop)        \n",
    "    plt.savefig(f'worker_{id}_eval_matrix.png')\n",
    "    \n",
    "    dataframe = pd.DataFrame(detail_out).transpose()\n",
    "    dataframe.to_csv(f\"worker_{id}_eval_table.csv\")\n",
    "\n",
    "\n",
    "# 결과 표에 곡명, 장르별로 정렬, Prof/Non-prof 구별 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font_path = 'malgun.ttf'\n",
    "font_prop = fm.FontProperties(fname=font_path, size=20)\n",
    "\n",
    "\n",
    "out = convert_result_to_dict(total_test_ids, total_rank, meta)\n",
    "detail_out = convert_result_to_rec_title(total_test_ids, total_recommends, total_rank, meta)\n",
    "\n",
    "keys = sorted(out.keys())\n",
    "rank_array = np.asarray([out[x] for x in keys])\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "ax = plt.gca()\n",
    "plt.imshow(1/(rank_array+1))\n",
    "plt.colorbar()\n",
    "ax.set_yticks(list(range(len(rank_array))))\n",
    "ax.set_yticklabels(keys)\n",
    "for label in ax.get_yticklabels() :\n",
    "    label.set_fontproperties(font_prop)\n",
    "plt.savefig(f'worker_{id}_eval_matrix.png')\n",
    "\n",
    "dataframe = pd.DataFrame(detail_out).transpose()\n",
    "dataframe.to_csv(f\"worker_{id}_eval_table.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.insert(1, 'Class', [flo_test_meta[x]['해당 요건'] for x in dataframe[0].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataframe.sort_values('Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "humm_meta = [x['meta'] for x in humm_test_loader.dataset.contours]\n",
    "humm_meta[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.insert(0, 'Class', [x['해당 요건'] for x in ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta[total_recommends[0][-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_songs_in_name = []\n",
    "def id_to_name(idx, meta):\n",
    "    if 'artist_name' in meta[idx]:\n",
    "        return f'{meta[idx][\"artist_name\"]} - {meta[idx][\"track_name\"]}'\n",
    "    else:\n",
    "        return f'{meta[idx][\"artist_name_basket\"][0]} - {meta[idx][\"track_name\"]}'\n",
    "for rec in total_recommends:\n",
    "    rec_songs_in_name.append([id_to_name(idx, meta) for idx in rec[:3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_result_to_rec_title(total_test_ids, total_recommends, total_rank, meta, humm_meta, k=3):\n",
    "    out = {}\n",
    "    for idx in total_test_ids:\n",
    "        out[meta[idx]['artist_name'] + ' - ' + meta[idx]['track_name']] = [idx] + [ [] for i in range(5)]\n",
    "    \n",
    "    for idx, rec, r, humm in zip(total_test_ids, total_recommends, total_rank, humm_meta):\n",
    "        target = out[meta[idx]['artist_name'] + ' - ' + meta[idx]['track_name']]\n",
    "        string =  \"\\n\".join([f'Rec rank: {r+1}'] + [id_to_name(idx, meta) for idx in rec[:k]]\n",
    "                            + [f'Group: {humm[\"singer_group\"]}', f'Singer ID: {humm[\"singer_id\"]}', f'Gender: {humm[\"singer_gender\"]}', f'Humm type: {humm[\"humming_type\"]}'])\n",
    "        if humm['singer_group'] == 'P':\n",
    "            if target[1] == []:\n",
    "                target[1] = string\n",
    "            else:\n",
    "                target[2] =  string\n",
    "        else:\n",
    "            if target[3] ==[]:\n",
    "                target[3] =  string\n",
    "            elif target[4] ==[]:\n",
    "                target[4] =  string\n",
    "            else:\n",
    "                target[5] =  string\n",
    "\n",
    "    return out\n",
    "\n",
    "test_out = convert_result_to_rec_title(total_test_ids, total_recommends, total_rank, meta, humm_meta)\n",
    "\n",
    "dataframe = pd.DataFrame(test_out).transpose()\n",
    "dataframe.to_csv(f\"worker_{id}_eval_table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_keys = dataframe.to_dict()[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_out = [{x: out[x]} for x in sorted_keys]\n",
    "sorted_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv('worker_483461_87k_eval_table_score0.648.csv')\n",
    "dataframe30k = pd.read_csv('worker_483461_eval_table_score0.708.csv')\n",
    "dataframe_old30k = pd.read_csv('worker_482492_eval_table_score0.72.csv')\n",
    "dataframe_old87k = pd.read_csv('worker_482492_87k_eval_table_score0.64.csv')\n",
    "dataframe_1024 = pd.read_csv('worker_485391_87k_eval_table_top100.656_mrr0.5042581410498366.csv')\n",
    "dataframe_ete = pd.read_csv('worker_484078_87k_eval_table_top100.58_mrr0.41014762349891215.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_dict = dataframe.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean( 1/ np.asarray([int(x[str(y)].split('\\n')[0].split(': ')[-1]) for x in csv_dict for y in range(1,6)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_dict[0][str(1)].split('\\n')[0].split(': ')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=np.asarray([int(x[str(y)].split('\\n')[0].split(': ')[-1]) for x in csv_dict for y in range(1,6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = [dataframe_old30k, dataframe_old87k,  dataframe30k, dataframe, dataframe_1024]\n",
    "target = [dataframe, dataframe_ete]\n",
    "plt.figure(figsize=(10,10))\n",
    "for df in target:\n",
    "    csv_dict = df.to_dict('records')\n",
    "    rank= np.asarray([int(x[str(y)].split('\\n')[0].split(': ')[-1]) for x in csv_dict for y in range(1,6)])\n",
    "    plt.plot([ np.mean(rank<=i+1) for i in range(30)])\n",
    "\n",
    "# plt.legend(['Train30k, Test30k','Train30k, Test87k', 'Train87k, Test30k', 'Train87k, Test87k'], fontsize=20)\n",
    "plt.legend(['Melody-based', 'End-to-end'], fontsize=20)\n",
    "\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}